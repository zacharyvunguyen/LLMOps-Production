{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Create a new Assistant with File Search Enabled\n",
    "Create a new assistant with file_search enabled in the tools parameter of the Assistant."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccfd1b1cd8a25ed5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:14:59.517594Z",
     "start_time": "2024-07-24T15:14:58.385268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<openai.OpenAI at 0x1088fd410>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from config import api_key\n",
    "client = OpenAI(api_key=api_key)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Story Assistant\",\n",
    "  instructions=\"You are a motivator who answers the question based on the story file\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:14:59.827928Z",
     "start_time": "2024-07-24T15:14:59.530834Z"
    }
   },
   "id": "826aa7fe0caeeb11",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Upload Files and Add Them to a Vector Store\n",
    "\n",
    "- **Purpose**: Use the Vector Store object for file access via the file_search tool.\n",
    "- **Tasks**:\n",
    "  - **Upload Files**: \n",
    "    - Upload your files.\n",
    "    - Create a Vector Store to contain the files.\n",
    "  - **Monitor Processing Status**:\n",
    "    - Poll the status of the Vector Store until all files are no longer in the `in_progress` state.\n",
    "    - Ensure all content has finished processing.\n",
    "- **Tools**: \n",
    "  - Use SDK helpers for uploading files and polling the status in one step."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e6eaabc5c2a15b2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store caled \"Financial Statements\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"Story Text\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"story.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:11.231063Z",
     "start_time": "2024-07-24T15:17:09.061218Z"
    }
   },
   "id": "cf13cae883f3aa59",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "VectorStore(id='vs_ZxX2FblVNT4KZtcKxEPVhxnF', created_at=1721834229, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1721834229, metadata={}, name='Story Text', object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:15.880836Z",
     "start_time": "2024-07-24T15:17:15.868867Z"
    }
   },
   "id": "6549f2763e72a052",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Update the assistant to use the new Vector Store\n",
    "To make the files accessible to your assistant, update the assistant’s tool_resources with the new vector_store id."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4741f5dc9a273f48"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:28.719049Z",
     "start_time": "2024-07-24T15:17:28.524700Z"
    }
   },
   "id": "a3af92eb3d93c485",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Create a thread\n",
    "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e69a72959fd827a6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_y61cnIzANXOpymW9X0knOJfN'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"pdf/cigna_member_handbook_2024.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    " \n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"what is the story about?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    " \n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:34.115567Z",
     "start_time": "2024-07-24T15:17:32.695263Z"
    }
   },
   "id": "b6724b9b9255fbc6",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Thread(id='thread_IjKOA0zGePLVYW5YJxW94HJK', created_at=1721834253, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_y61cnIzANXOpymW9X0knOJfN'])))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:35.320867Z",
     "start_time": "2024-07-24T15:17:35.299717Z"
    }
   },
   "id": "be1285dc900e915f",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Create a run and check the output\n",
    "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d86001d1cd6b7a8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story titled \"The Odyssey of Lumina: Illuminating Lives\" is about a brilliant inventor named Dr. Michael Greene who creates a revolutionary wearable device called \"Lumina.\" Lumina emits a gentle light that enhances cognitive function, mood, and overall well-being. Initially, Lumina is widely praised and adopted by individuals from various sectors, helping them reach their full potential.\n",
      "\n",
      "However, as time progresses, unintended consequences arise. People become overly dependent on Lumina, sometimes neglecting their natural abilities and experiencing withdrawal symptoms when they are without it. Dr. Greene faces a moral dilemma about whether Lumina is truly beneficial or if it has become a hindrance to human progress.\n",
      "\n",
      "As public scrutiny intensifies and sales decline, Dr. Greene decides to revamp Lumina to address the concerns. He assembles a team of experts to redesign the product, resulting in Lumina 2.0, which includes customizable settings and built-in reminders for balance and moderation. This improved version receives positive feedback, and Lumina is embraced as a tool rather than a crutch.\n",
      "\n",
      "Dr. Greene's journey highlights the importance of innovation balanced with responsibility. Eventually, Lumina becomes a symbol of resilience, adaptability, and the enduring human spirit, making a profound impact on humanity  .\n"
     ]
    }
   ],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:47.944719Z",
     "start_time": "2024-07-24T15:17:38.241652Z"
    }
   },
   "id": "260d94ad0b2599b7",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'asst_1HPpPpECEaExqjuVVOQqh0SU'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant.id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:17:47.953996Z",
     "start_time": "2024-07-24T15:17:47.942230Z"
    }
   },
   "id": "40c5425290108fe0",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-24T15:15:23.360283Z",
     "start_time": "2024-07-24T15:15:23.355094Z"
    }
   },
   "id": "f0b87ae4170ed112",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
