{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Create a new Assistant with File Search Enabled\n",
    "Create a new assistant with file_search enabled in the tools parameter of the Assistant."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccfd1b1cd8a25ed5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-16T14:59:03.683824Z",
     "start_time": "2024-07-16T14:59:02.632349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<openai.OpenAI at 0x10c228c10>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from config import api_key\n",
    "client = OpenAI(api_key=api_key)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"Story Assistant\",\n",
    "  instructions=\"You are a motivator who answers the question based on the story file\",\n",
    "  model=\"gpt-4o\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T15:00:22.041761Z",
     "start_time": "2024-07-16T15:00:21.619141Z"
    }
   },
   "id": "826aa7fe0caeeb11",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Upload Files and Add Them to a Vector Store\n",
    "\n",
    "- **Purpose**: Use the Vector Store object for file access via the file_search tool.\n",
    "- **Tasks**:\n",
    "  - **Upload Files**: \n",
    "    - Upload your files.\n",
    "    - Create a Vector Store to contain the files.\n",
    "  - **Monitor Processing Status**:\n",
    "    - Poll the status of the Vector Store until all files are no longer in the `in_progress` state.\n",
    "    - Ensure all content has finished processing.\n",
    "- **Tools**: \n",
    "  - Use SDK helpers for uploading files and polling the status in one step."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e6eaabc5c2a15b2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store caled \"Financial Statements\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"Story Text\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"story.txt\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T15:01:57.423859Z",
     "start_time": "2024-07-16T15:01:52.915232Z"
    }
   },
   "id": "cf13cae883f3aa59",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "VectorStore(id='vs_hJpAJocyD7kagKj3VmLN7OZc', created_at=1721142113, file_counts=FileCounts(cancelled=0, completed=0, failed=0, in_progress=0, total=0), last_active_at=1721142113, metadata={}, name='Story Text', object='vector_store', status='completed', usage_bytes=0, expires_after=None, expires_at=None)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T15:05:13.317391Z",
     "start_time": "2024-07-16T15:05:13.309918Z"
    }
   },
   "id": "6549f2763e72a052",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Update the assistant to use the new Vector Store\n",
    "To make the files accessible to your assistant, update the assistant’s tool_resources with the new vector_store id."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4741f5dc9a273f48"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T15:04:21.313928Z",
     "start_time": "2024-07-16T15:04:20.653099Z"
    }
   },
   "id": "a3af92eb3d93c485",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Create a thread\n",
    "You can also attach files as Message attachments on your thread. Doing so will create another vector_store associated with the thread, or, if there is already a vector store attached to this thread, attach the new files to the existing thread vector store. When you create a Run on this thread, the file search tool will query both the vector_store from your assistant and the vector_store on the thread."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e69a72959fd827a6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_stMQ0QuhXUNJIv58dVFemWqb'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(\"pdf/cigna_member_handbook_2024.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    " \n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"what is the story about?\",\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    " \n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T17:56:11.335421Z",
     "start_time": "2024-07-16T17:56:09.257245Z"
    }
   },
   "id": "b6724b9b9255fbc6",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Thread(id='thread_phkJwOJgnHnNugFoH0EMpOvB', created_at=1721152571, metadata={}, object='thread', tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=['vs_stMQ0QuhXUNJIv58dVFemWqb'])))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T17:56:12.172672Z",
     "start_time": "2024-07-16T17:56:12.164239Z"
    }
   },
   "id": "be1285dc900e915f",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Create a run and check the output\n",
    "Now, create a Run and observe that the model uses the File Search tool to provide a response to the user’s question.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d86001d1cd6b7a8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The story, titled \"The Odyssey of Lumina: Illuminating Lives,\" revolves around Dr. Michael Greene, a visionary inventor who creates \"Lumina,\" a groundbreaking wearable device designed to enhance human cognitive function, mood, and overall well-being through the emission of a gentle light. Initially, Lumina is highly successful and well-received, with people from various walks of life using it to boost their productivity and potential.\n",
      "\n",
      "However, challenges soon arise. As people become overly dependent on Lumina, they neglect their own innate abilities, and some experience withdrawal symptoms. This dependency leads to a moral dilemma for Dr. Greene: he questions whether his invention is a force for good or a crutch hindering human progress.\n",
      "\n",
      "Facing declining sales and increasing scrutiny, Dr. Greene takes decisive action by assembling a team of experts to reevaluate Lumina's design. They develop Lumina 2.0, which includes features to promote balance and moderation. The new version allows users to customize settings and includes reminders for breaks and healthy habits. This version is positively received, and Lumina transitions from being seen as a crutch to a supplementary tool that supports natural abilities.\n",
      "\n",
      "Ultimately, Dr. Greene learns valuable lessons about the power of responsible innovation and the true meaning of success. Lumina becomes a symbol of resilience, adaptability, and the enduring human spirit, serving as a beacon of positive change and inspiring people to embrace their potential and forge their paths forward  .\n"
     ]
    }
   ],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T17:56:26.161796Z",
     "start_time": "2024-07-16T17:56:14.798504Z"
    }
   },
   "id": "260d94ad0b2599b7",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'asst_94o2aTFbFx5WSKWjhm8fsR1o'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant.id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T15:40:45.738119Z",
     "start_time": "2024-07-16T15:40:45.724784Z"
    }
   },
   "id": "40c5425290108fe0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b87ae4170ed112"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
